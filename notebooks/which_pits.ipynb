{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c530afe9",
   "metadata": {},
   "source": [
    "# Pits, SMP, and SSA Oh My \n",
    "\n",
    "The notebook attempts to use the database to find all the SMP profiles associated with Pits where SSA was also measured \n",
    "\n",
    "We have micro-ct data from the pits:\n",
    "\n",
    "* 1S17  \n",
    "* 2N13\n",
    "* 2S16 \n",
    "* 2S7 \n",
    "* 9C16\n",
    "\n",
    "We can use these to determine which of the SMP profile file names should be downloaded. We are currently only focused on the smp profiles nearest the pit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "685ce02d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the function to get connect to the db\n",
    "from snowexsql.db import get_db\n",
    "\n",
    "# Our Integrating Sphere SSA and SMP data in the DB are under layers\n",
    "from snowexsql.data import LayerData\n",
    "\n",
    "# Grab our handy functions to convert records to dataframes\n",
    "from snowexsql.conversions import query_to_geopandas\n",
    "\n",
    "import geopandas as gpd \n",
    "import pandas as pd \n",
    "\n",
    "import os \n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "\n",
    "# This is what you will use for all of hackweek to access the db\n",
    "db_name = 'snow:hackweek@db.snowexdata.org/snowex'\n",
    "\n",
    "# Using the function get_db, we receive 2 ways to interact with the database\n",
    "engine, session = get_db(db_name, credentials=None)\n",
    "\n",
    "# Sites where Micro-ct was collected\n",
    "sites = ['1S17', '2N13', '2S16', '2S7','9C16']\n",
    "\n",
    "# Change this to overwrite the files we stored in git, this will create git tracked changes in data\n",
    "write_ssa_to_file = False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63a5a8c3",
   "metadata": {},
   "source": [
    "## Find our SMP profiles\n",
    "\n",
    "We are interested in the SMP profiles taken at the pit, indicated in the pandas dataframe as p\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b00a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_filename_from_meta(meta_row):\n",
    "    \"\"\"\n",
    "    Reproduce the filename from the smp metadata xls/csv sheet.\n",
    "    \"\"\"    \n",
    "    f_str = 'SNEX20_SMP_S{}M{}_{}_{}.PNT'\n",
    "    \n",
    "    # instrument IDs were used to indicate. In the meta 19 sometimes has a b but not in the file names\n",
    "    serial_num  = meta_row['SMP instrument # '].replace('b','')\n",
    "    f_suffix =  meta_row['Fname sufix']\n",
    "    site_id = meta_row['Pit ID']\n",
    "    dt_str = meta_row['Date'].replace('-','').split(' ')[0]\n",
    "    return f_str.format(serial_num, f_suffix, site_id, dt_str)\n",
    " \n",
    "    \n",
    "# Import the SMP meta file as a dataframe \n",
    "smp_meta = pd.read_csv('../data/SNEX20_SMP_FieldNotes.csv', header=9)    \n",
    "    \n",
    "for sid in sites:\n",
    "    print(f'\\nProfiles next to the pit at site = {sid}:')\n",
    "    # filter the meta on pit id\n",
    "    ind1 = smp_meta['Pit ID'] == sid\n",
    "    \n",
    "    # Grab by orientation only at the pit \n",
    "    ind2 = smp_meta['Orientation'] == 'P'\n",
    "    \n",
    "    # Apply our filters\n",
    "    df = smp_meta.loc[ind1 & ind2]\n",
    "    \n",
    "    df['filename'] = df.apply(lambda row: get_filename_from_meta(row), axis=1)\n",
    "    print(df['filename'].values)\n",
    "                                                        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2cb869a",
   "metadata": {},
   "source": [
    "# Grab our SSA profiles\n",
    "\n",
    "Grab our SSA by site id and write the profile to data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2824be42",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = '../data/SSA/'\n",
    "\n",
    "if not os.path.isdir(output):\n",
    "    os.mkdir(output)\n",
    "\n",
    "for sid in sites:\n",
    "    # Grab all the columns in layer data\n",
    "    qry = session.query(LayerData)\n",
    "    # Only grab ssa\n",
    "    qry = qry.filter(LayerData.type == 'specific_surface_area')\n",
    "    \n",
    "    # Filter by this pit\n",
    "    qry = qry.filter(LayerData.site_id == sid)\n",
    "\n",
    "    # Order the values by depth \n",
    "    qry = qry.order_by('depth')\n",
    "    \n",
    "    # Cast it to geopandas \n",
    "    df = query_to_geopandas(qry, engine)\n",
    "    \n",
    "    # Values in layers are always strings so cast this as a float\n",
    "    df['value'] = df['value'].astype(float)\n",
    "    \n",
    "    # Prove to ourselves there only one day this was done at these pits.\n",
    "    date = df['date'].unique()\n",
    "    print(date)\n",
    "    \n",
    "    # Save the data \n",
    "    if write_ssa_to_file:\n",
    "        out_f = os.path.join(output, f'DB_SSA_{sid}.csv')\n",
    "        print(f'Writing data out to {out_f}...')\n",
    "        df.to_csv(out_f, index=False)\n",
    "        \n",
    "    plt.plot(df['value'], df['depth'])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274bd303",
   "metadata": {},
   "outputs": [],
   "source": [
    "session.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d08a186",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
